---
layout: post
author: zhao
title: 浅谈Hadoop
modified: 2015-07-17
tags: [Hadoop]
image:
  feature: pic-4.jpg
---

##写在前面
接触Hadoop差不多有一年多的时间了，一年前正是研一下学期，自己还没有从电子信息专业的思维以及基础过度到计算机领域，整个人懵懵懂懂，无所特长。对于Linux、Java、数据结构和网络这些乱七八糟的东西仅仅只能说是了解，期间又承受着信息检索、模式识别、机器学习和数据挖掘这类高端名词的冲刷，整个人过的比较茫然和无奈。

起初，我对于Hadoop是没什么热爱情绪的，首先不知道这是什么东西，其次Hadoop所需的专业知识其实是非常多的。最后一直接触Hadoop比较多的原因主要有三个：一、Hadoop的动手操作比较多，特别是在安装的过程中，需要各种Linux的操作，整个初期的学习基本都是在动手中度过的，由于Linux和Java基础薄弱，顺利完成Hadoop集群的搭建，基本上是靠各种通宵熬夜；二、研一下学期在上课的过程中到了高能所计算中心实习（多谢何家乐一直细心地带我入门），主要负责的就是大数据平台的运维工作，期间三个多月的时间基本都是在做和Hadoop相关工作；三、七月份回实验室后继续维护实验室集群，又紧跟本科生的大数据导论课程开课，跟着当了助教。由于教学需求，搭建了一个六七十个节点的小型集群，没事了就帮学生答答疑，调调代码，期间被一些本科生的发散思维所触动，老老实实地又啃了几遍《Hadoop权威指南》，随对Hadoop了解加深一层。

经此过程，虽说不是专门研究Hadoop，亦对Hadoop又所了解，加之随后的学习中频繁接触云计算和大数据领域中诸如Spark、Storm、CloudFoundry、OpenStack和Docker这些开源项目以及，对Hadoop也算有所感触，深知不同时期对一些概念和原理理解的程度不同，所以整理一篇文章记录现时思维，以供日后参考。

文章的主要内容主要是对Hadoop的理解，但不仅限于Hadoop，亦掺杂自己对其它概念的各种思考（主要是和Hadoop的对比），个人才疏学浅，难免有各种不准确和理解偏差的地方，欢迎指点和交流。

##何为大数据？

>在维克托·迈尔-舍恩伯格及肯尼斯·库克耶编写的《大数据时代》中大数据指不用随机分析法（抽样调查）这样的捷径，而采用所有数据进行分析处理。大数据的4V特点：Volume（大量）、Velocity（高速）、Variety（多样）、Value（价值）。

这本书是我接触最早的一本大数据的书，概念阐释的比较清楚，在书中着重强调了大数据和传统抽样调查的区别，这也是我对大数据最早的理解。其大致意思如下：比如问卷调查，如果想调查全中国14亿的平均身高，我们很难统计到每个人的信息，因此采用抽样的方式，每个群体抽出来一部分人，用这些人的统计结果来代替全中国的人。那么在大数据时代，我们不做抽样了，我们通过互联网的手段来获取某方面的全部数据，以此来计算出全国人的平均身高，这是和传统方式非常不同的地方。

>Not the size，it's the style .                            ——Doug Cutting

Doug Cutting是Hadoop创始人，也可以说是发起者，在他来清华的一次演讲中，有人问到什么是BigData，他的回答如上。这点，学习过Hadoop的人应该都会有所感触。因为我们在学习的时候，很难每个人都有一个大的分布式集群让你来学习和折腾，我们一般的学习都是单节点的Hadoop集群。但是即使是单节点的Hadoop，它的操作方式和思路也是符合大数据的思想的。

那么什么是大数据呢，个人感觉很难有一个准确的定义，但是可以从一些处理问题的方式和思路来分析它。

如今我们张口闭口都谈的大数据是什么：首先，基本上能生产数据的领域都已经大数据化了，医疗大数据、教育大数据、空间大数据、交通大数据，等等，全部都是大数据了，也就是说，大数据已经跨越了领域范围，很难以某个行业的标签也分辨大数据了。然后，看看做什么工作的是大数据。记得一年前有一次大数据大会，几个同学兴致勃勃地去参加，当时被弄得晕头转向的。为什么?所有的人都在说自己在搞大数据，有数据可视化的，有数据存储的，有数据安全的，当时还没明白什么是大数据，就被各种的概念给玩坏了。如今反思，其实大可以不必纠结这些概念到底哪个准确，大家都不在意到底什么是大数据，只要这个名字能给所有参与的人带来利益即可。

如今也接触了不少的大数据的相关知识，也认识了不少搞大数据的朋友。略微总结一下自己所知道的和大数据相关的工作内容：大数据平台运维，大数据平台开发，大数据清洗，机器学习，等等等等，有很多不同的名字和方向。但是站在个人的角度来讲，我认为大数据一次火热登场的原因之一是Hadoop的出现，而和Hadoop相关度比较高首先是大数据平台的运维和开发，至于机器学习和数据挖掘这些领域，本身没有太大变化，变化只是这个潮流而已。

##何为Hadoop

身处Hadoop时代，很多人都想搞大数据的，至少在我身边很多人都是如此。既然要搞大数据，Hadoop是很难跑的掉的，那么Hadoop是什么？下面的一些内容我会按照自己的理解从不同的角度来介绍Hadoop。

###仅仅是工具

个人认为，首先Hadoop仅仅是一个工具，正如Mysql一样，是一个工具，不同是Hadoop提供了更新的一些东西，更好的一些解决方案。

###存储和计算框架

Hadoop的革新之处有两个：非结构化存储和分布式计算，其实这些技术一直都有，但是都没有Hadoop造成的影响大，这也得益于开源活动。

Hadoop首先提供了一种自己特有的文件系统：HDFS，它在Linux之上做了一层封装，能够提供大规模地集群存储功能。然后是特有的MApReduce计算框架，分布式协同计算。

站在个人角度理解，HAdoop有几点吸引人的地方：

 - 分布式存储（能够整合足够多服务器来协同存储）
 - 存储备份（HDFS自带备份冗余功能，比如说HDFS默认的备份数量是3，正常情况下，一台服务器宕机，完全不影响数据的完整性）
 - 分布式计算（至少我认为这一点是影响非常大的，计算这一块着实解决了很多单机不能解决的问题，能非常好地利用资源）


###PaaS平台

我认为，在某种程度上，Hadoop比较符合云计算中的PaaS的一部分概念，Hadoop为开发者（数据相关工作者）提供了一个计算中间件，目前IBM的Bluemix和MicroSoft的Azure均已经把Hadoop继承在了各自的公有云平台中，它是对开发者提供的一层服务，使用Hadoop可以处理大规模的数据问题。

###Hadoop和其它

随着Hadoop的崛起，出现了一大批的开源软件：Hbase、Hive、Spark、Storm...... 这些有的是依赖于Hadoop，有的完全独立，这些软件各有自己擅长的领域和其独到之处。因此身边也有一些朋友偶尔会纠结到底学哪个呢？

Doug在清华的演讲中说到了Hadoop的一些存在意义，举了一个例子，这个例子正是PPT的图片，是个手机。大致意思是：手机可以干很多事，比如照相，但是照相的功能不如一些专业的相机。但是有一点可以确定，大家用手机照相的时间比相机多，为什么呢，因为手机一直在你身边，你什么时候都可以用，而且除了照相，我还可以把照片分享，总的来说，就是已经存在，而且方便。

Hadoop也类似，现在有很多的计算框架，Spark、Storm这类的。这种情况不必否认其他的存在，Hadoop大家会比较熟悉，而且应用很广泛，在你需要的时候，可能你就有一个hadoop的集群环境，有些计算可能Spark性能更好，但是hadoop也可以做，方便使用。http://blog.csdn.net/zhaodedong/article/details/46288607

##如何学Hadoop
最初学习Hadoop的感觉，这可能是一个比较快入门的领域，学习成本会低一些，见效快。经过一段时间接触后，发现其实有这种想法的原因是自己对Hadoop了解太少。经历过这么多坑后，记录一下自己认为学习Hadoop需要学的东西。

 - Java（Hadoop也可以用python，但是毕竟最好的方式是Java，因此Java要掌握到一定的程度，不然在写MR程序的时候会比较通读）
 - Linux（Hadoop目前已经有Windows版本的，但是主要的操作系统还是Linux。想学好Hadoop，至少要对Linux有一定程度的理解。作为零基础的Linux学习者，在安装Hadoop的时候会遇到各种各样奇葩问题，比如ssh配置不对，环境变量出问题，不懂权限管理。）
 - 机器学习（大数据挖掘会和机器学习相关，但是这不是纯搞算法的一种类型，纯搞算法的，其实和Hadoop没什么关系，比较偏向于算法本身的性能，但是在Hadoop领域里面涉及到数据挖掘的相关的内容，就需要具备一定的机器学习实力。）

